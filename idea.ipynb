{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import Word\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(pd.read_csv('words.csv')).T[1]\n",
    "prepositions = np.array(pd.read_csv('prepositions.csv')).T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "parts of speech:\n",
    "    ADJ: a\n",
    "    ADJ_SAT: s\n",
    "    ADV: r\n",
    "    NOUN: n\n",
    "    VERB: v\n",
    "\n",
    "wn.synsets('word'): returns all interpretations of the given word\n",
    "\n",
    "word.definitions: returns all definitions of the given word\n",
    "\n",
    "wn.syset('word.n.##'): returns the ##-th synset of the word\n",
    "\n",
    "Word('word'): returns the word as a string\n",
    "\n",
    "synset._pos: returns part of speech\n",
    "\n",
    "synset.\n",
    "    / hypernyms(): returns more general synsets\n",
    "    / hyponyms(): returns more specific synsets\n",
    "    / member/part/substance_holonyms(): returns container synsets\n",
    "    / member/part/substance_meronyms(): returns component synsets\n",
    "    / similar_tos(): returns synonym synsets\n",
    "    \n",
    "synset.lemmas(): returns synonym synsets\n",
    "synset.lemma_names(): returns synonym strings\n",
    "synset.lemma_names()[0]: returns the synset as a string\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get list of all alphabetic-character-only WordNet words.'''\n",
    "\n",
    "'''words = [ n for n in wn.all_lemma_names() if n.isalpha() ]\n",
    "pd.DataFrame(words).to_csv('words.csv')'''\n",
    "\n",
    "'''Import list of most common prepositions and their frequency.'''\n",
    "\n",
    "'''preps = np.array(pd.read_html(requests.get(\n",
    "    'https://www.talkenglish.com/vocabulary/top-50-prepositions.aspx').content)[-1][1])\n",
    "freq = np.array(pd.read_html(requests.get(\n",
    "    'https://www.talkenglish.com/vocabulary/top-50-prepositions.aspx').content)[-1][2])\n",
    "\n",
    "prep_distr = []\n",
    "for p in range(len(preps)):\n",
    "    for f in range(freq[p]):\n",
    "        prep_distr.append(preps[p])\n",
    "        \n",
    "prep_distr = np.array(prep_distr)     \n",
    "np.random.shuffle(prep_distr)\n",
    "df = pd.DataFrame(prep_distr)\n",
    "df.to_csv('prepositions.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Define set of semantic relations based on which the program performs association.'''\n",
    "\n",
    "relations = [\n",
    "    'hypernyms'\n",
    "    , 'hyponyms'\n",
    "    , 'member_holonyms'\n",
    "    , 'part_holonyms'\n",
    "    , 'substance_holonyms'\n",
    "    , 'member_meronyms'\n",
    "    , 'substance_meronyms'\n",
    "    , 'part_meronyms'\n",
    "    , 'similar_tos'\n",
    "]\n",
    "\n",
    "def relate(synset, relation):\n",
    "    \n",
    "    if relation == 'hypernyms':\n",
    "        return synset.hypernyms()\n",
    "    \n",
    "    if relation == 'hyponyms':\n",
    "        return synset.hyponyms()\n",
    "    \n",
    "    if relation == 'member_holonyms':\n",
    "        return synset.member_holonyms()\n",
    "    \n",
    "    if relation == 'part_holonyms':\n",
    "        return synset.part_holonyms()\n",
    "    \n",
    "    if relation == 'substance_holonyms':\n",
    "        return synset.substance_holonyms()\n",
    "    \n",
    "    if relation == 'member_meronyms':\n",
    "        return synset.member_meronyms()\n",
    "    \n",
    "    if relation == 'part_meronyms':\n",
    "        return synset.part_meronyms()\n",
    "    \n",
    "    if relation == 'substance_meronyms':\n",
    "        return synset.substance_meronyms()\n",
    "    \n",
    "    if relation == 'similar_tos':\n",
    "        return synset.similar_tos()\n",
    "    \n",
    "    raise ValueError(str(relation) + ': Not a recognized type of semantic relation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Spreading activation.'''\n",
    "\n",
    "def spreading(word):\n",
    "    \n",
    "    global relations, words\n",
    "    \n",
    "    synsets = list(n for n in wn.synsets(word) if n._lemma_names[0] in words)\n",
    "    \n",
    "    if len(synsets) == 0:\n",
    "        return None\n",
    "    \n",
    "    synset = synsets[int(np.random.rand() * len(synsets))]\n",
    "    \n",
    "    connections = list(\n",
    "        list(n for n in relate(synset, relation) if (n._lemma_names[0] in words and n._lemma_names[0] != word))\n",
    "        for relation in relations)\n",
    "    connections = list(n for n in connections if len(n) != 0)\n",
    "    \n",
    "    if len(connections) == 0:\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        connections = np.concatenate(np.array(connections))\n",
    "        return connections[int(np.random.rand() * len(connections))]._lemma_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Random association function.'''    \n",
    "        \n",
    "def associate(word):\n",
    "        \n",
    "    global words\n",
    "    \n",
    "    levels = min(5, (int(np.random.exponential(scale = 2)) + 1))\n",
    "        \n",
    "    for l in range(levels):\n",
    "        new_word = spreading(word)\n",
    "        if new_word == None:\n",
    "            word = words[int(np.random.rand() * len(words))]\n",
    "        else:\n",
    "            word = new_word\n",
    "        \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Generate random pieces of text.'''\n",
    "\n",
    "def generator(pieces, print_iter):\n",
    "    \n",
    "    global prepositions, words\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for p in range(pieces):\n",
    "        \n",
    "        length = min(10, (2 + int(np.random.exponential(scale = 2))))\n",
    "        word = words[int(np.random.rand() * len(words))]\n",
    "        text = word + ' '\n",
    "\n",
    "        for l in range(length):\n",
    "            \n",
    "            if np.random.binomial(n = 1, p = 0.3):\n",
    "                text += prepositions[int(np.random.rand() * len(prepositions))]\n",
    "                    \n",
    "            else:\n",
    "                if np.random.binomial(n = 1, p = 0.1):\n",
    "                    text += words[int(np.random.rand() * len(words))]\n",
    "\n",
    "                else:\n",
    "                    t = 0\n",
    "                    while word in text and t < 10:\n",
    "                        word = associate(word)\n",
    "                        t += 1\n",
    "                    if t == 10:\n",
    "                        text += words[int(np.random.rand() * len(words))]\n",
    "                    else:\n",
    "                        text += word\n",
    "                    \n",
    "            if l < (length - 1):\n",
    "                text += ' '\n",
    "                \n",
    "        samples.append(text)\n",
    "        \n",
    "        if (p % print_iter) == 0:\n",
    "            print('Iteration: ', p, '\\n-----------------\\n')\n",
    "        \n",
    "    return np.array(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
