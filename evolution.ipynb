{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Hanga\\programok\\Anaconda\\envs\\py35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ipynb.fs.full.idea import generator, associate\n",
    "from ipynb.fs.full.encode import encode, flatten, clean\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Hanga\\programok\\Anaconda\\envs\\py35\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('evaluator_tree.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Evolution parameters.'''\n",
    "\n",
    "population_size = 1000\n",
    "generations = 500\n",
    "min_fitness = 0.5\n",
    "copy_prop = 0.1\n",
    "mutation_size = 0.5\n",
    "\n",
    "'''Length for encoding strings.'''\n",
    "length = max(list(len(t) for t in np.array(pd.read_csv('DATA.csv')['0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generation_zero = np.array(pd.read_csv('generation_zero.csv')['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \n",
      "-----------------\n",
      "\n",
      "Iteration:  100 \n",
      "-----------------\n",
      "\n",
      "Iteration:  200 \n",
      "-----------------\n",
      "\n",
      "Iteration:  300 \n",
      "-----------------\n",
      "\n",
      "Iteration:  400 \n",
      "-----------------\n",
      "\n",
      "Iteration:  500 \n",
      "-----------------\n",
      "\n",
      "Iteration:  600 \n",
      "-----------------\n",
      "\n",
      "Iteration:  700 \n",
      "-----------------\n",
      "\n",
      "Iteration:  800 \n",
      "-----------------\n",
      "\n",
      "Iteration:  900 \n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Give birth to generation zero.'''\n",
    "\n",
    "generation_zero = generator(population_size, 100)\n",
    "pd.DataFrame(generation_zero).to_csv('generation_zero.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = np.array(pd.read_csv('words.csv')).T[1]\n",
    "prepositions = np.array(pd.read_csv('prepositions.csv')).T[1]\n",
    "all_words = np.concatenate((words, prepositions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Evaluate fitness of specimens.'''\n",
    "\n",
    "def evaluate(generation):\n",
    "    \n",
    "    global model, min_fitness, length\n",
    "    \n",
    "    fitness = model.predict(encode(generation, length))\n",
    "    avg_score = fitness.mean()\n",
    "    survivors = fitness.argsort()[-int(len(generation) * min_fitness):][::-1]\n",
    "    creeps = fitness.argsort()[:int(len(generation) * min_fitness)][::-1]\n",
    "    \n",
    "    return np.array([survivors, creeps, avg_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Sort fittest specimens.'''\n",
    "\n",
    "def sort_next_gen(prev_gen, survivors):\n",
    "    \n",
    "    next_gen = []\n",
    "    \n",
    "    for s in survivors:\n",
    "        next_gen.append(prev_gen[s])\n",
    "        \n",
    "    return np.array(next_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Generate new samples by mutating some specimens.'''\n",
    "\n",
    "def mutate(specimens):\n",
    "    \n",
    "    global mutation_size, all_words\n",
    "    \n",
    "    mutations = []\n",
    "        \n",
    "    for spec in specimens:\n",
    "        elements = spec.split(' ')\n",
    "        change, copy = train_test_split(\n",
    "            elements, train_size = mutation_size, test_size = 1 - mutation_size)\n",
    "        new = []\n",
    "        for w in change:\n",
    "            if wn.synsets(w) != []:\n",
    "                new.append(associate(w))\n",
    "            else:\n",
    "                new.append(all_words[int(np.random.rand() * len(all_words))])\n",
    "        diff_order = np.array(elements)\n",
    "        np.random.shuffle(diff_order)\n",
    "        mutation1 = ''\n",
    "        mutation2 = ''\n",
    "        for e in range(len(elements)):\n",
    "            mutation2 += diff_order[e]\n",
    "            if elements[e] in change:\n",
    "                mutation1 += new[change.index(elements[e])]\n",
    "            else:\n",
    "                mutation1 += elements[e]\n",
    "            if e < (len(elements) - 1):\n",
    "                mutation1 += ' '\n",
    "                mutation2 += ' '\n",
    "                    \n",
    "        mutations.append(mutation1)\n",
    "        mutations.append(mutation2)\n",
    "        \n",
    "    return np.array(mutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Generate new samples by crossing over some specimens.\n",
    "\n",
    "def crossover(specimens):\n",
    "    \n",
    "    children = []\n",
    "    \n",
    "    for i in range(2):\n",
    "    \n",
    "        singles = list(specimens)\n",
    "\n",
    "        while len(singles) > 1:\n",
    "\n",
    "            pair1 = singles[int(len(singles) * np.random.rand())]\n",
    "            singles.remove(pair1)\n",
    "            pair2 = singles[int(len(singles) * np.random.rand())]\n",
    "            singles.remove(pair2)\n",
    "            elements1 = pair1.split(' ')\n",
    "            elements2 = pair2.split(' ')\n",
    "            child1 = ''\n",
    "            child2 = ''\n",
    "            for e in range(int(len(elements1) / 2)):\n",
    "                child1 += elements1[e] + ' '\n",
    "            for e in range(int(len(elements2) / 2)):\n",
    "                child2 += elements2[e] + ' '\n",
    "            for e in range(int(len(elements1) / 2), len(elements1)):\n",
    "                child2 += elements1[e]\n",
    "                if e < (len(elements1) - 1):\n",
    "                    child2 += ' '\n",
    "            for e in range(int(len(elements2) / 2), len(elements2)):\n",
    "                child1 += elements2[e]\n",
    "                if e < (len(elements2) - 1):\n",
    "                    child1 += ' '\n",
    "            children.append(child1)\n",
    "            children.append(child2)\n",
    "\n",
    "        if len(singles) == 1:\n",
    "            children.append(singles[0])\n",
    "        \n",
    "    return np.array(children)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation:  0\n",
      "Some members:  ['stop oversea resoluteness' 'with dinnertime mealtime'\n",
      " 'sauna simpleton troposphere' 'smoothly expurgate aimless'\n",
      " 'chew without chomp']\n",
      "-------------------------------------\n",
      "\n",
      "Generation:  10\n",
      "Some members:  ['buffalo to game' 'sumac on sumac' 'of baffle by' 'md fleet by'\n",
      " 'owe frustration have']\n",
      "-------------------------------------\n",
      "\n",
      "Generation:  20\n",
      "Some members:  ['dig dig costume' 'usaf bos ooh' 'from vomit cut' 'to bare net'\n",
      " 'in to accept']\n",
      "-------------------------------------\n",
      "\n",
      "Generation:  30\n",
      "Some members:  ['hang cox to' 'halogen of finn' 'on in softwood'\n",
      " 'tensimeter tensimeter rage' 'sheet on of']\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-60bf9bbb993e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcopied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_gen_material\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy_prop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcopy_prop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mmutated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmutating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mgeneration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreeps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-52023080968a>\u001b[0m in \u001b[0;36mmutate\u001b[1;34m(specimens)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                 \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massociate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Hanga\\Rajk\\KURZUSOK\\Machine Learning\\Modeling Creativity\\idea.ipynb\u001b[0m in \u001b[0;36massociate\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;34m\"        return None\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;34m\"    \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[1;34m\"    else:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[1;34m\"        connections = np.concatenate(np.array(connections))\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;34m\"        return connections[int(np.random.rand() * len(connections))]._lemma_names[0]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Hanga\\Rajk\\KURZUSOK\\Machine Learning\\Modeling Creativity\\idea.ipynb\u001b[0m in \u001b[0;36mspreading\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;34m\"'''Spreading activation.'''\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;34m\"def spreading(word):\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;34m\"    \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;34m\"    global relations, words\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Hanga\\Rajk\\KURZUSOK\\Machine Learning\\Modeling Creativity\\idea.ipynb\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;34m\"'''Spreading activation.'''\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;34m\"def spreading(word):\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;34m\"    \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;34m\"    global relations, words\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Hanga\\Rajk\\KURZUSOK\\Machine Learning\\Modeling Creativity\\idea.ipynb\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    165\u001b[0m    \"source\": [\n\u001b[0;32m    166\u001b[0m     \u001b[1;34m\"'''Spreading activation.'''\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m     \u001b[1;34m\"def spreading(word):\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;34m\"    \\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Perform evolution process.'''\n",
    "\n",
    "generation = generation_zero\n",
    "scores = []\n",
    "\n",
    "for g in range(generations):\n",
    "    \n",
    "    evaluated = evaluate(generation)\n",
    "    scores.append(evaluated[2])\n",
    "    next_gen_material = sort_next_gen(generation, evaluated[0])\n",
    "    creeps = sort_next_gen(generation, evaluated[1])\n",
    "    np.random.shuffle(creeps)\n",
    "    creeps = creeps[:int(population_size * min_fitness * copy_prop)]\n",
    "    copied, mutating = train_test_split(next_gen_material, train_size = copy_prop, test_size = 1 - copy_prop)\n",
    "    \n",
    "    mutated = mutate(mutating)\n",
    "    \n",
    "    generation = np.concatenate((copied, creeps, mutated))\n",
    "    np.random.shuffle(generation)\n",
    "    \n",
    "    if (g % 10) == 0:\n",
    "        print('Generation: ', g)\n",
    "        print('Some members: ', generation[:5])\n",
    "        print('-------------------------------------\\n')\n",
    "    if (g % 50) == 0:\n",
    "        pd.DataFrame(generation).to_csv('evolving_tree' + str(g) + '.csv')\n",
    "    \n",
    "print(generation)\n",
    "df = pd.DataFrame(generation)\n",
    "df.to_csv('final_generation_tree.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
